Output dir: experiments_avconvtasnet/AV_ConvTasNet_backend-nccl-2_20230522-163852
Train AV_ConvTasNet on VoxCeleb2-2Mix
- PyTorch version: 1.11.0
- Ignite version: 0.4.12
- GPU Device: NVIDIA A100-SXM4-80GB
- CUDA version: 11.3
- CUDNN version: 8200


Configuration:
	seed: 42
	batch_size: 8
	optimizer: Adam
	optimizer_args: {'lr': 0.001, 'amsgrad': True}
	epochs: 400
	epoch_length: 2
	outputpath: experiments_avconvtasnet/AV_ConvTasNet_backend-nccl-2_20230522-163852
	model: AV_ConvTasNet
	train_scp: /mnt/user/linjiuxin/ssd/voxceleb2/meta/train.scp
	train_dur: /mnt/user/linjiuxin/ssd/voxceleb2/meta/train_dur
	cv_scp: /mnt/user/linjiuxin/ssd/voxceleb2/meta/val.scp
	cv_dur: /mnt/user/linjiuxin/ssd/voxceleb2/meta/val_dur
	eval_scp: /mnt/user/linjiuxin/ssd/voxceleb2/meta/test.scp
	eval_dur: /mnt/user/linjiuxin/ssd/voxceleb2/meta/test_dur
	loss: SI_SNR
	n_saved: 1
	num_workers: 6
	validate_every: 1
	with_amp: False
	backend: nccl
	nproc_per_node: 2
	default_args: {'outputpath': 'experiments', 'batch_size': 4, 'num_workers': 6, 'mixer_args': {}, 'n_saved': 1, 'epochs': 400, 'optimizer': 'Adam', 'optimizer_args': {'lr': 0.001}}
	mixer_args: {}



Distributed setting:
	backend: nccl
	world size: 2


Engine run starting with max_epochs=400.
Learning rate: 0.001

Epoch 1 - Evaluation time (seconds): 101.16 - Val metrics:
 	si-snr loss: 18.144715330471247
Epoch[1] Complete. Time taken: 00:01:47.641
Learning rate: 0.001

Epoch 2 - Evaluation time (seconds): 101.90 - Val metrics:
 	si-snr loss: 8.948608788438499
Epoch[2] Complete. Time taken: 00:01:45.786
Learning rate: 0.001

Epoch 3 - Evaluation time (seconds): 100.51 - Val metrics:
 	si-snr loss: 6.201093484799321
Epoch[3] Complete. Time taken: 00:01:43.531
Learning rate: 0.001

Epoch 4 - Evaluation time (seconds): 101.08 - Val metrics:
 	si-snr loss: 4.646705115565096
Epoch[4] Complete. Time taken: 00:01:44.134
Learning rate: 0.001
