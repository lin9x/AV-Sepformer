Output dir: experiments_avsepformer/AV_Sepformer_backend-nccl-2_20230522-162829
Train AV_Sepformer on VoxCeleb2-2Mix
- PyTorch version: 1.11.0
- Ignite version: 0.4.12
- GPU Device: NVIDIA A100-SXM4-80GB
- CUDA version: 11.3
- CUDNN version: 8200


Configuration:
	seed: 42
	batch_size: 1
	optimizer: Adam
	optimizer_args: {'lr': 0.00015, 'amsgrad': True}
	epochs: 400
	epoch_length: 2
	outputpath: experiments_avsepformer/AV_Sepformer_backend-nccl-2_20230522-162829
	model: AV_Sepformer
	train_scp: /mnt/user/linjiuxin/ssd/voxceleb2/meta/train.scp
	train_dur: /mnt/user/linjiuxin/ssd/voxceleb2/meta/train_dur
	cv_scp: /mnt/user/linjiuxin/ssd/voxceleb2/meta/val.scp
	cv_dur: /mnt/user/linjiuxin/ssd/voxceleb2/meta/val_dur
	eval_scp: /mnt/user/linjiuxin/ssd/voxceleb2/meta/test.scp
	eval_dur: /mnt/user/linjiuxin/ssd/voxceleb2/meta/test_dur
	loss: SI_SNR
	n_saved: 1
	num_workers: 6
	validate_every: 1
	with_amp: False
	backend: nccl
	nproc_per_node: 2
	default_args: {'outputpath': 'experiments', 'batch_size': 4, 'num_workers': 6, 'mixer_args': {}, 'n_saved': 1, 'epochs': 400, 'optimizer': 'Adam', 'optimizer_args': {'lr': 0.001}}
	mixer_args: {}
	master_port: 2333



Distributed setting:
	backend: nccl
	world size: 2


Engine run starting with max_epochs=400.
Learning rate: 0.00015

Epoch 1 - Evaluation time (seconds): 491.28 - Val metrics:
 	si-snr loss: 6.45149453125
Epoch[1] Complete. Time taken: 00:08:15.590
Learning rate: 0.00015
